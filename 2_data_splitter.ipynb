{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0gP7zt+pxkNCg2AdBTEWW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","# For Colab/Google Drive integration:\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/FinRL/final')  # Change to your project folder in Drive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvih5nLhEF_p","executionInfo":{"status":"ok","timestamp":1754133429911,"user_tz":-300,"elapsed":1953,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}},"outputId":"b5385517-bb48-40f1-8f79-1e3e723ecbd0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","from typing import Tuple, Dict, List\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"UkVJXd04fTq2","executionInfo":{"status":"ok","timestamp":1754133431054,"user_tz":-300,"elapsed":1140,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def split_data_from_single_csv(original_csv_path: str, data_dir: str = \"./data\",\n","                              train_ratio: float = 0.7, val_ratio: float = 0.15,\n","                              test_ratio: float = 0.15, timeframe: str = \"1sec\") -> Tuple[str, str, str]:\n","    \"\"\"\n","    Split a single CSV file into train, validation, and test sets chronologically.\n","\n","    Args:\n","        original_csv_path: Path to the original CSV file\n","        data_dir: Directory to save split files\n","        train_ratio: Ratio for training data (default: 0.7)\n","        val_ratio: Ratio for validation data (default: 0.15)\n","        test_ratio: Ratio for test data (default: 0.15)\n","        timeframe: Timeframe identifier for file naming (default: \"1sec\")\n","\n","    Returns:\n","        Tuple of (train_csv_path, val_csv_path, test_csv_path)\n","    \"\"\"\n","    print(f\"Splitting data from {original_csv_path} (timeframe: {timeframe})...\")\n","\n","    # Create timeframe-specific directory\n","    timeframe_dir = os.path.join(data_dir, timeframe)\n","    os.makedirs(timeframe_dir, exist_ok=True)\n","    print(f\"Output directory: {timeframe_dir}\")\n","\n","    # Read the original CSV file\n","    df = pd.read_csv(original_csv_path)\n","    print(f\"Original data shape: {df.shape}\")\n","\n","    # Ensure the data is sorted by time\n","    if 'system_time' in df.columns:\n","        df = df.sort_values('system_time')\n","        print(\"Sorted data by system_time\")\n","    else:\n","        print(\"Warning: No 'system_time' column found. Data will not be sorted.\")\n","\n","    # Calculate split indices\n","    total_rows = len(df)\n","    train_end = int(total_rows * train_ratio)\n","    val_end = int(total_rows * (train_ratio + val_ratio))\n","\n","    # Split the data\n","    train_df = df.iloc[:train_end]\n","    val_df = df.iloc[train_end:val_end]\n","    test_df = df.iloc[val_end:]\n","\n","    print(f\"Split indices: Train=0:{train_end}, Val={train_end}:{val_end}, Test={val_end}:{total_rows}\")\n","    print(f\"Split sizes: Train={len(train_df):,}, Val={len(val_df):,}, Test={len(test_df):,}\")\n","\n","    # Generate output file paths with timeframe\n","    base_name = os.path.splitext(os.path.basename(original_csv_path))[0]\n","    # Remove timeframe suffix if it exists in the base name\n","    if base_name.endswith(('_1sec', '_1min', '_5min')):\n","        base_name = base_name.rsplit('_', 1)[0]\n","\n","    train_csv_path = os.path.join(timeframe_dir, f\"{base_name}_{timeframe}_train_70.csv\")\n","    val_csv_path = os.path.join(timeframe_dir, f\"{base_name}_{timeframe}_val_15.csv\")\n","    test_csv_path = os.path.join(timeframe_dir, f\"{base_name}_{timeframe}_test_15.csv\")\n","\n","    # Save split files\n","    train_df.to_csv(train_csv_path, index=False)\n","    val_df.to_csv(val_csv_path, index=False)\n","    test_df.to_csv(test_csv_path, index=False)\n","\n","    print(\"✓ Split files saved:\")\n","    print(f\"  - Train: {train_csv_path}\")\n","    print(f\"  - Val: {val_csv_path}\")\n","    print(f\"  - Test: {test_csv_path}\")\n","\n","    return train_csv_path, val_csv_path, test_csv_path"],"metadata":{"id":"WGLj4J4lfVIL","executionInfo":{"status":"ok","timestamp":1754133431093,"user_tz":-300,"elapsed":35,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def verify_split_files(train_csv_path: str, val_csv_path: str, test_csv_path: str, timeframe: str = \"1sec\") -> bool:\n","    \"\"\"\n","    Verify that all split files exist and have the expected structure.\n","\n","    Args:\n","        train_csv_path: Path to training CSV file\n","        val_csv_path: Path to validation CSV file\n","        test_csv_path: Path to test CSV file\n","        timeframe: Timeframe identifier for verification\n","\n","    Returns:\n","        True if all files exist and are valid, False otherwise\n","    \"\"\"\n","    print(f\"\\nVerifying split files (timeframe: {timeframe})...\")\n","\n","    files_to_check = [\n","        (\"Train\", train_csv_path),\n","        (\"Validation\", val_csv_path),\n","        (\"Test\", test_csv_path)\n","    ]\n","\n","    all_valid = True\n","    total_records = 0\n","\n","    for split_name, file_path in files_to_check:\n","        if os.path.exists(file_path):\n","            try:\n","                df = pd.read_csv(file_path)\n","                total_records += len(df)\n","                print(f\"✓ {split_name}: {file_path} ({len(df):,} rows, {len(df.columns)} columns)\")\n","\n","                # Check if timeframe is in filename\n","                if timeframe not in file_path:\n","                    print(f\"  ⚠️  Warning: Timeframe '{timeframe}' not found in filename\")\n","\n","            except Exception as e:\n","                print(f\"✗ {split_name}: {file_path} - Error reading file: {e}\")\n","                all_valid = False\n","        else:\n","            print(f\"✗ {split_name}: {file_path} - File not found\")\n","            all_valid = False\n","\n","    if all_valid:\n","        print(f\"✓ All split files are valid! Total records: {total_records:,}\")\n","    else:\n","        print(\"✗ Some split files have issues!\")\n","\n","    return all_valid"],"metadata":{"id":"3BYAz5pjfXAY","executionInfo":{"status":"ok","timestamp":1754133431107,"user_tz":-300,"elapsed":19,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def get_split_file_paths(base_name: str, data_dir: str = \"./data\", timeframe: str = \"1sec\") -> Dict[str, str]:\n","    \"\"\"\n","    Get the expected file paths for split files based on timeframe.\n","\n","    Args:\n","        base_name: Base name of the original file (without extension)\n","        data_dir: Directory containing split files\n","        timeframe: Timeframe identifier (\"1sec\", \"1min\", \"5min\")\n","\n","    Returns:\n","        Dictionary with keys 'train', 'val', 'test' and corresponding file paths\n","    \"\"\"\n","    # Remove timeframe suffix if it exists in the base name\n","    if base_name.endswith(('_1sec', '_1min', '_5min')):\n","        base_name = base_name.rsplit('_', 1)[0]\n","\n","    timeframe_dir = os.path.join(data_dir, timeframe)\n","    file_paths = {\n","        'train': os.path.join(timeframe_dir, f\"{base_name}_{timeframe}_train_70.csv\"),\n","        'val': os.path.join(timeframe_dir, f\"{base_name}_{timeframe}_val_15.csv\"),\n","        'test': os.path.join(timeframe_dir, f\"{base_name}_{timeframe}_test_15.csv\")\n","    }\n","\n","    return file_paths"],"metadata":{"id":"0KTopwT6fhIP","executionInfo":{"status":"ok","timestamp":1754133431120,"user_tz":-300,"elapsed":12,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def check_split_files_exist(base_name: str, data_dir: str = \"./data\", timeframe: str = \"1sec\") -> bool:\n","    \"\"\"\n","    Check if split files exist for a given timeframe.\n","\n","    Args:\n","        base_name: Base name of the original file (without extension)\n","        data_dir: Directory containing split files\n","        timeframe: Timeframe identifier (\"1sec\", \"1min\", \"5min\")\n","\n","    Returns:\n","        True if all split files exist, False otherwise\n","    \"\"\"\n","    file_paths = get_split_file_paths(base_name, data_dir, timeframe)\n","\n","    all_exist = True\n","    for split_type, file_path in file_paths.items():\n","        if not os.path.exists(file_path):\n","            print(f\"Missing {split_type} file: {file_path}\")\n","            all_exist = False\n","        else:\n","            print(f\"✓ {split_type} file exists: {file_path}\")\n","\n","    return all_exist"],"metadata":{"id":"e7pWSMHKfkqh","executionInfo":{"status":"ok","timestamp":1754133431135,"user_tz":-300,"elapsed":14,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def run_data_splitting_pipeline(input_file: str, timeframe: str = \"1sec\",\n","                               output_dir: str = \"./data\"):\n","    \"\"\"\n","    Run the complete data splitting pipeline.\n","\n","    Args:\n","        input_file: Path to input CSV file\n","        timeframe: Timeframe for splitting (\"1sec\", \"1min\", \"5min\")\n","        output_dir: Directory to save split files\n","    \"\"\"\n","    print(\"=\" * 60)\n","    print(f\"Data Splitting Pipeline - {timeframe}\")\n","    print(\"=\" * 60)\n","\n","    # Check if input file exists\n","    if not os.path.exists(input_file):\n","        print(f\"Error: Input file {input_file} not found!\")\n","        return None\n","\n","    # Validate timeframe\n","    supported_timeframes = [\"1sec\", \"1min\", \"5min\"]\n","    if timeframe not in supported_timeframes:\n","        print(f\"Error: Unsupported timeframe '{timeframe}'. Supported: {', '.join(supported_timeframes)}\")\n","        return None\n","\n","    try:\n","        # Perform the split\n","        train_path, val_path, test_path = split_data_from_single_csv(\n","            original_csv_path=input_file,\n","            data_dir=output_dir,\n","            train_ratio=0.7,\n","            val_ratio=0.15,\n","            test_ratio=0.15,\n","            timeframe=timeframe\n","        )\n","\n","        # Verify the split files\n","        verify_split_files(train_path, val_path, test_path, timeframe)\n","\n","        print(\"\\n\" + \"=\" * 60)\n","        print(\"Data splitting completed successfully!\")\n","        print(\"=\" * 60)\n","\n","        return train_path, val_path, test_path\n","\n","    except Exception as e:\n","        print(f\"Error during data splitting: {e}\")\n","        return None"],"metadata":{"id":"y6DGU-aZfls9","executionInfo":{"status":"ok","timestamp":1754133431158,"user_tz":-300,"elapsed":17,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Configuration 1: 1-second data splitting\n","def config_1sec():\n","    \"\"\"Configuration for 1-second data splitting.\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"CONFIGURATION 1: 1-SECOND DATA SPLITTING\")\n","    print(\"=\"*60)\n","\n","    input_file = \"./data/BTC_1sec_with_sentiment_risk_train.csv\"\n","\n","    if os.path.exists(input_file):\n","        result = run_data_splitting_pipeline(input_file, timeframe=\"1sec\")\n","        if result:\n","            print(\"✓ 1-second data splitting completed!\")\n","        else:\n","            print(\"✗ 1-second data splitting failed!\")\n","    else:\n","        print(f\"File {input_file} not found. Please ensure the file exists in the /data directory.\")"],"metadata":{"id":"QHLkbfidfpRL","executionInfo":{"status":"ok","timestamp":1754133431185,"user_tz":-300,"elapsed":18,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Configuration 2: 1-minute data splitting\n","def config_1min():\n","    \"\"\"Configuration for 1-minute data splitting.\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"CONFIGURATION 2: 1-MINUTE DATA SPLITTING\")\n","    print(\"=\"*60)\n","\n","    input_file = \"./data/BTC_1min_with_sentiment_risk_train.csv\"\n","\n","    if os.path.exists(input_file):\n","        result = run_data_splitting_pipeline(input_file, timeframe=\"1min\")\n","        if result:\n","            print(\"✓ 1-minute data splitting completed!\")\n","        else:\n","            print(\"✗ 1-minute data splitting failed!\")\n","    else:\n","        print(f\"File {input_file} not found. Please ensure the file exists in the /data directory.\")"],"metadata":{"id":"20ca0helfrvW","executionInfo":{"status":"ok","timestamp":1754133431208,"user_tz":-300,"elapsed":21,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Configuration 3: 5-minute data splitting\n","def config_5min():\n","    \"\"\"Configuration for 5-minute data splitting.\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"CONFIGURATION 3: 5-MINUTE DATA SPLITTING\")\n","    print(\"=\"*60)\n","\n","    input_file = \"./data/BTC_5min_with_sentiment_risk_train.csv\"\n","\n","    if os.path.exists(input_file):\n","        result = run_data_splitting_pipeline(input_file, timeframe=\"5min\")\n","        if result:\n","            print(\"✓ 5-minute data splitting completed!\")\n","        else:\n","            print(\"✗ 5-minute data splitting failed!\")\n","    else:\n","        print(f\"File {input_file} not found. Please ensure the file exists in the /data directory.\")"],"metadata":{"id":"ZWtpaNSLftko","executionInfo":{"status":"ok","timestamp":1754133431260,"user_tz":-300,"elapsed":42,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["config_1sec()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9EYZ6XBf0YG","executionInfo":{"status":"ok","timestamp":1754133590518,"user_tz":-300,"elapsed":159259,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}},"outputId":"51c8f29a-adb1-46fb-af8b-75051f23a9c2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","CONFIGURATION 1: 1-SECOND DATA SPLITTING\n","============================================================\n","============================================================\n","Data Splitting Pipeline - 1sec\n","============================================================\n","Splitting data from ./data/BTC_1sec_with_sentiment_risk_train.csv (timeframe: 1sec)...\n","Output directory: ./data/1sec\n","Original data shape: (494749, 158)\n","Sorted data by system_time\n","Split indices: Train=0:346324, Val=346324:420536, Test=420536:494749\n","Split sizes: Train=346,324, Val=74,212, Test=74,213\n","✓ Split files saved:\n","  - Train: ./data/1sec/BTC_1sec_with_sentiment_risk_train_1sec_train_70.csv\n","  - Val: ./data/1sec/BTC_1sec_with_sentiment_risk_train_1sec_val_15.csv\n","  - Test: ./data/1sec/BTC_1sec_with_sentiment_risk_train_1sec_test_15.csv\n","\n","Verifying split files (timeframe: 1sec)...\n","✓ Train: ./data/1sec/BTC_1sec_with_sentiment_risk_train_1sec_train_70.csv (346,324 rows, 158 columns)\n","✓ Validation: ./data/1sec/BTC_1sec_with_sentiment_risk_train_1sec_val_15.csv (74,212 rows, 158 columns)\n","✓ Test: ./data/1sec/BTC_1sec_with_sentiment_risk_train_1sec_test_15.csv (74,213 rows, 158 columns)\n","✓ All split files are valid! Total records: 494,749\n","\n","============================================================\n","Data splitting completed successfully!\n","============================================================\n","✓ 1-second data splitting completed!\n"]}]},{"cell_type":"code","source":["config_1min()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O2rNe1Muf2HJ","executionInfo":{"status":"ok","timestamp":1754133594760,"user_tz":-300,"elapsed":4239,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}},"outputId":"34a84250-975c-4778-9455-66d3d14e9c32"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","CONFIGURATION 2: 1-MINUTE DATA SPLITTING\n","============================================================\n","============================================================\n","Data Splitting Pipeline - 1min\n","============================================================\n","Splitting data from ./data/BTC_1min_with_sentiment_risk_train.csv (timeframe: 1min)...\n","Output directory: ./data/1min\n","Original data shape: (8249, 158)\n","Sorted data by system_time\n","Split indices: Train=0:5774, Val=5774:7011, Test=7011:8249\n","Split sizes: Train=5,774, Val=1,237, Test=1,238\n","✓ Split files saved:\n","  - Train: ./data/1min/BTC_1min_with_sentiment_risk_train_1min_train_70.csv\n","  - Val: ./data/1min/BTC_1min_with_sentiment_risk_train_1min_val_15.csv\n","  - Test: ./data/1min/BTC_1min_with_sentiment_risk_train_1min_test_15.csv\n","\n","Verifying split files (timeframe: 1min)...\n","✓ Train: ./data/1min/BTC_1min_with_sentiment_risk_train_1min_train_70.csv (5,774 rows, 158 columns)\n","✓ Validation: ./data/1min/BTC_1min_with_sentiment_risk_train_1min_val_15.csv (1,237 rows, 158 columns)\n","✓ Test: ./data/1min/BTC_1min_with_sentiment_risk_train_1min_test_15.csv (1,238 rows, 158 columns)\n","✓ All split files are valid! Total records: 8,249\n","\n","============================================================\n","Data splitting completed successfully!\n","============================================================\n","✓ 1-minute data splitting completed!\n"]}]},{"cell_type":"code","source":["config_5min()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mLQIjcsHf3I7","executionInfo":{"status":"ok","timestamp":1754133595550,"user_tz":-300,"elapsed":780,"user":{"displayName":"Taimoor Ahmed","userId":"12202674111508394168"}},"outputId":"358061bf-16bb-4e80-d0f9-7395e57a7563"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","CONFIGURATION 3: 5-MINUTE DATA SPLITTING\n","============================================================\n","============================================================\n","Data Splitting Pipeline - 5min\n","============================================================\n","Splitting data from ./data/BTC_5min_with_sentiment_risk_train.csv (timeframe: 5min)...\n","Output directory: ./data/5min\n","Original data shape: (1651, 158)\n","Sorted data by system_time\n","Split indices: Train=0:1155, Val=1155:1403, Test=1403:1651\n","Split sizes: Train=1,155, Val=248, Test=248\n","✓ Split files saved:\n","  - Train: ./data/5min/BTC_5min_with_sentiment_risk_train_5min_train_70.csv\n","  - Val: ./data/5min/BTC_5min_with_sentiment_risk_train_5min_val_15.csv\n","  - Test: ./data/5min/BTC_5min_with_sentiment_risk_train_5min_test_15.csv\n","\n","Verifying split files (timeframe: 5min)...\n","✓ Train: ./data/5min/BTC_5min_with_sentiment_risk_train_5min_train_70.csv (1,155 rows, 158 columns)\n","✓ Validation: ./data/5min/BTC_5min_with_sentiment_risk_train_5min_val_15.csv (248 rows, 158 columns)\n","✓ Test: ./data/5min/BTC_5min_with_sentiment_risk_train_5min_test_15.csv (248 rows, 158 columns)\n","✓ All split files are valid! Total records: 1,651\n","\n","============================================================\n","Data splitting completed successfully!\n","============================================================\n","✓ 5-minute data splitting completed!\n"]}]}]}